{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Zadanie 5 \u2013 Test modeli i wersji prompt\u00f3w systemowych\n", "Testujemy r\u00f3\u017cne modele Ollama oraz dwa style prompt\u00f3w do generowania broszury firmowej."]}, {"cell_type": "code", "metadata": {}, "source": ["import requests\n", "from bs4 import BeautifulSoup\n", "import ollama\n", "from IPython.display import Markdown, display"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["def get_page_text(url):\n", "    response = requests.get(url)\n", "    soup = BeautifulSoup(response.text, 'html.parser')\n", "    return soup.get_text()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["system_prompt_1 = \"Jeste\u015b ekspertem marketingu. Napisz profesjonaln\u0105 broszur\u0119 firmy na podstawie tre\u015bci strony.\"\n", "system_prompt_2 = \"Napisz lekk\u0105 i przyjazn\u0105 broszur\u0119 o firmie. U\u017cyj przyst\u0119pnego j\u0119zyka. Odpowied\u017a w markdown.\""], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["def create_brochure_prompt(text):\n", "    return f\"Oto tre\u015b\u0107 strony firmy. Napisz na jej podstawie broszur\u0119: {text[:4000]}\""], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["def generate_brochure(url, model='llama3.2', prompt_version=1):\n", "    text = get_page_text(url)\n", "    system_prompt = system_prompt_1 if prompt_version == 1 else system_prompt_2\n", "    prompt = create_brochure_prompt(text)\n", "    messages = [\n", "        {\"role\": \"system\", \"content\": system_prompt},\n", "        {\"role\": \"user\", \"content\": prompt}\n", "    ]\n", "    response = ollama.chat(model=model, messages=messages)\n", "    return response['message']['content']"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Przyk\u0142ad testu na r\u00f3\u017cnych modelach i promptach\n", "models = ['llama3.2', 'llama3.3', 'deepseek-r1:8b', 'gemma2:27b']\n", "urls = ['https://pl.wikipedia.org/wiki/OpenAI', 'https://www.anaconda.com']\n", "\n", "for url in urls:\n", "    for model in models:\n", "        for version in [1, 2]:\n", "            print(f\"\\nModel: {model} | URL: {url} | Prompt wersja: {version}\\n\")\n", "            try:\n", "                result = generate_brochure(url, model=model, prompt_version=version)\n", "                display(Markdown(result))\n", "            except Exception as e:\n", "                print(f\"B\u0142\u0105d przy {model}, wersja {version}: {e}\")"], "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}